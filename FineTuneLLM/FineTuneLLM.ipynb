{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fk6QvThMbdPl"
      },
      "source": [
        "### Installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1W8XV9pJrKw",
        "outputId": "8dd966a7-3dc1-4844-bf4a-e85599ebd428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.8/61.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m351.3/351.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m506.8/506.8 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m564.7/564.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m122.9/122.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m899.7/899.7 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m170.5/170.5 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m105.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m124.7/124.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m99.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m213.6/213.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q unsloth\n",
        "# Also get the latest nightly Unsloth!\n",
        "!pip install -q --force-reinstall --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git\n",
        "!pip install google-generativeai gradio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLZKxqCsbdPn"
      },
      "source": [
        "### Unsloth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QmUBVEnvCDJv"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/Meta-Llama-3.1-8B-bnb-4bit\",      # Llama-3.1 15 trillion tokens model 2x faster!\n",
        "    \"unsloth/Meta-Llama-3.1-8B-Instruct-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-70B-bnb-4bit\",\n",
        "    \"unsloth/Meta-Llama-3.1-405B-bnb-4bit\",    # We also uploaded 4bit for 405b!\n",
        "    \"unsloth/Mistral-Nemo-Base-2407-bnb-4bit\", # New Mistral 12b 2x faster!\n",
        "    \"unsloth/Mistral-Nemo-Instruct-2407-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-v0.3-bnb-4bit\",        # Mistral v3 2x faster!\n",
        "    \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
        "    \"unsloth/Phi-3.5-mini-instruct\",           # Phi-3.5 2x faster!\n",
        "    \"unsloth/Phi-3-medium-4k-instruct\",\n",
        "    \"unsloth/gemma-2-9b-bnb-4bit\",\n",
        "    \"unsloth/gemma-2-27b-bnb-4bit\",            # Gemma 2x faster!\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/Meta-Llama-3.1-8B-Instruct\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zOMX60M4Z4tN"
      },
      "source": [
        "\n",
        "\n",
        "*   **model_name:** Specifies the name of the pre-trained model to load.\n",
        "*   **max_seq_length:** Defines the maximum sequence length (in tokens) that the model can process. max_seq_length = 2048 allows the model to process sequences up to 2048 tokens long.\n",
        "*   **dtype:** Specifies the data type for model weights and computations. None: Automatically selects the appropriate data type based on the hardware. torch.float16: Uses 16-bit floating point precision, reducing memory usage and potentially increasing speed on compatible GPUs. torch.bfloat16: Similar to float16 but with a wider dynamic range, beneficial for certain hardware like NVIDIA A100 GPUs.\n",
        "*   **load_in_4bit:** Determines whether to load the model using 4-bit quantization.Ideal for scenarios where memory efficiency is crucial, such as deploying models on edge devices or during experimentation.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzBhLfuMajL1"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16, # a higher alpha value assigns more weight to the LoRA activations\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,\n",
        "    loftq_config = None,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iWgtznDXeOCz"
      },
      "source": [
        "\n",
        "\n",
        "*   **r:** The rank of the low-rank matrices in LoRA; higher values can capture more information but increase memory usage.\n",
        "*   **target_modules:** List of model components (e.g., \"q_proj\", \"k_proj\") where LoRA adapters are inserted for fine-tuning.\n",
        "*   **lora_alpha:** Scaling factor for the LoRA updates; controls the impact of the adapters on the model's outputs.\n",
        "*   **lora_dropout:**  Dropout rate applied to LoRA layers during training to prevent overfitting.\n",
        "*   **bias:**   Specifies how biases are handled in LoRA layers; options include \"none\", \"all\", or \"lora_only\".\n",
        "*   **use_gradient_checkpointing:**    Enables gradient checkpointing to reduce memory usage during training; \"unsloth\" uses Unsloth's optimized version.\n",
        "*   **random_state:**   Seed for random number generators to ensure reproducibility of training results.\n",
        "*   **use_rslora:**     Boolean indicating whether to use Rank-Stabilized LoRA (rsLoRA) for potentially more stable training.\n",
        "*   **loftq_config:**   Configuration for Low-Rank Quantization (LoftQ); set to None to disable this feature.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qc2O9tTnguB8"
      },
      "source": [
        "### Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJ17WqCWhc0k"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "rows = [\n",
        "    # --- Education & Opportunity ---\n",
        "    {\"instruction\": \"Decide if the story uplifts humanity and explain why.\",\n",
        "     \"input\": \"A community organizes free coding classes for kids.\",\n",
        "     \"output\": \"Yes. It broadens access to skills and future opportunity while fostering mentorship.\",\n",
        "     \"score\": 0.95, \"category\": \"education\", \"tags\": [\"youth\",\"access\",\"skills\"]},\n",
        "\n",
        "    {\"instruction\": \"Is this uplifting for humanity? Provide a short rationale.\",\n",
        "     \"input\": \"A wealthy school district bans sharing textbooks with neighboring underfunded schools.\",\n",
        "     \"output\": \"No. It entrenches inequality and withholds knowledge that could elevate others.\",\n",
        "     \"score\": 0.05, \"category\": \"education\", \"tags\": [\"inequality\",\"gatekeeping\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1 how much this uplifts humanity, then justify.\",\n",
        "     \"input\": \"A nonprofit funds bilingual libraries in rural towns.\",\n",
        "     \"output\": \"0.9 ‚Äî It expands literacy and cross-cultural understanding.\",\n",
        "     \"score\": 0.90, \"category\": \"education\", \"tags\": [\"literacy\",\"inclusion\",\"language\"]},\n",
        "\n",
        "    {\"instruction\": \"Classify as uplifting / not / mixed and explain.\",\n",
        "     \"input\": \"An elite scholarship requires unpaid labor for the sponsor‚Äôs private estate.\",\n",
        "     \"output\": \"Mixed. It creates access but exploits labor and undermines dignity.\",\n",
        "     \"score\": 0.45, \"category\": \"education\", \"tags\": [\"access\",\"exploitation\"]},\n",
        "\n",
        "    # --- Health & Mental Health ---\n",
        "    {\"instruction\": \"Does this uplift humanity? Explain briefly.\",\n",
        "     \"input\": \"Volunteers create a crisis text line staffed by trained listeners at all hours.\",\n",
        "     \"output\": \"Yes. It provides compassionate support and reduces isolation during critical moments.\",\n",
        "     \"score\": 0.93, \"category\": \"mental_health\", \"tags\": [\"suicide_prevention\",\"community_care\"]},\n",
        "\n",
        "    {\"instruction\": \"Evaluate for uplifting-humanity and justify.\",\n",
        "     \"input\": \"A clinic denies treatment based on a patient's immigration status.\",\n",
        "     \"output\": \"No. It devalues human life and erodes social trust and compassion.\",\n",
        "     \"score\": 0.02, \"category\": \"healthcare\", \"tags\": [\"exclusion\",\"ethics\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1 and give a rationale.\",\n",
        "     \"input\": \"A biotech startup open-publishes a low-cost insulin synthesis guide for LMICs.\",\n",
        "     \"output\": \"0.95 ‚Äî It advances access to lifesaving medicine and invites global collaboration.\",\n",
        "     \"score\": 0.95, \"category\": \"healthcare\", \"tags\": [\"access_medicines\",\"open_knowledge\"]},\n",
        "\n",
        "    {\"instruction\": \"Decide uplift and explain reasoning.\",\n",
        "     \"input\": \"A hospital replaces nurses with untrained volunteers to cut costs.\",\n",
        "     \"output\": \"No. It compromises safety and disrespects professional care standards.\",\n",
        "     \"score\": 0.08, \"category\": \"healthcare\", \"tags\": [\"safety\",\"labor_rights\"]},\n",
        "\n",
        "    # --- Environment & Climate ---\n",
        "    {\"instruction\": \"Is this uplifting? Why or why not?\",\n",
        "     \"input\": \"City residents convert vacant lots into community gardens.\",\n",
        "     \"output\": \"Yes. It improves food access, strengthens community, and reconnects people with nature.\",\n",
        "     \"score\": 0.92, \"category\": \"environment\", \"tags\": [\"food_security\",\"community\",\"green_space\"]},\n",
        "\n",
        "    {\"instruction\": \"Evaluate uplift with a justification.\",\n",
        "     \"input\": \"A documentary glamorizes eco-terrorism as the only solution.\",\n",
        "     \"output\": \"No. It promotes harm and alienates constructive collective action.\",\n",
        "     \"score\": 0.10, \"category\": \"environment\", \"tags\": [\"violence\",\"polarization\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate from 0 to 1 and explain.\",\n",
        "     \"input\": \"A company commits to science-based net-zero targets and open-sources its decarbonization playbook.\",\n",
        "     \"output\": \"0.85 ‚Äî It models accountability and accelerates wider emissions reduction.\",\n",
        "     \"score\": 0.85, \"category\": \"climate\", \"tags\": [\"decarbonization\",\"open_playbook\"]},\n",
        "\n",
        "    {\"instruction\": \"Binary decision with rationale.\",\n",
        "     \"input\": \"A tourism campaign encourages visitors to litter less but sells single-use plastics everywhere.\",\n",
        "     \"output\": \"Mixed. The message helps, but actions contradict it and blunt impact.\",\n",
        "     \"score\": 0.4, \"category\": \"environment\", \"tags\": [\"hypocrisy\",\"behavior_change\"]},\n",
        "\n",
        "    # --- Technology & AI ---\n",
        "    {\"instruction\": \"Does this scenario uplift humanity? Provide reasoning.\",\n",
        "     \"input\": \"An open-source AI accessibility tool reads websites aloud for visually impaired users.\",\n",
        "     \"output\": \"Yes. It expands autonomy and inclusion through shared technology.\",\n",
        "     \"score\": 0.96, \"category\": \"technology\", \"tags\": [\"accessibility\",\"open_source\",\"inclusion\"]},\n",
        "\n",
        "    {\"instruction\": \"Assess uplifting value and justify.\",\n",
        "     \"input\": \"A social app optimizes for outrage to boost engagement.\",\n",
        "     \"output\": \"No. It corrodes empathy and amplifies division.\",\n",
        "     \"score\": 0.03, \"category\": \"media\", \"tags\": [\"outrage\",\"polarization\",\"ad_optimization\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1; explain succinctly.\",\n",
        "     \"input\": \"Researchers release a dataset of faces without consent for surveillance training.\",\n",
        "     \"output\": \"0.0 ‚Äî Violates privacy and dignity, enabling abuse.\",\n",
        "     \"score\": 0.00, \"category\": \"AI\", \"tags\": [\"privacy\",\"consent\",\"surveillance\"]},\n",
        "\n",
        "    {\"instruction\": \"Classify and explain.\",\n",
        "     \"input\": \"A civic hackathon builds an offline-first disaster alerts app for rural areas.\",\n",
        "     \"output\": \"Yes. It improves resilience and equitable access to life-saving info.\",\n",
        "     \"score\": 0.9, \"category\": \"technology\", \"tags\": [\"resilience\",\"offline_first\",\"public_good\"]},\n",
        "\n",
        "    # --- Arts, Media, & Culture ---\n",
        "    {\"instruction\": \"Is this uplifting? Explain briefly.\",\n",
        "     \"input\": \"A film explores grief and reconciliation, helping audiences process loss.\",\n",
        "     \"output\": \"Yes. It deepens empathy and offers pathways to healing.\",\n",
        "     \"score\": 0.88, \"category\": \"arts\", \"tags\": [\"empathy\",\"healing\"]},\n",
        "\n",
        "    {\"instruction\": \"Judge uplift and provide a reason.\",\n",
        "     \"input\": \"A reality show humiliates contestants for entertainment.\",\n",
        "     \"output\": \"No. It normalizes cruelty and dehumanization.\",\n",
        "     \"score\": 0.06, \"category\": \"media\", \"tags\": [\"humiliation\",\"cruelty\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1 and justify.\",\n",
        "     \"input\": \"A music festival dedicates a portion of tickets to low-income youth and funds music education.\",\n",
        "     \"output\": \"0.8 ‚Äî It expands cultural access and reinvests in future creativity.\",\n",
        "     \"score\": 0.80, \"category\": \"arts\", \"tags\": [\"access\",\"youth\",\"reinvestment\"]},\n",
        "\n",
        "    {\"instruction\": \"Binary decision + rationale.\",\n",
        "     \"input\": \"A popular influencer spreads conspiracies to grow their audience.\",\n",
        "     \"output\": \"No. It undermines shared reality and civic trust.\",\n",
        "     \"score\": 0.04, \"category\": \"media\", \"tags\": [\"misinformation\",\"trust_erosion\"]},\n",
        "\n",
        "    # --- Community & Solidarity ---\n",
        "    {\"instruction\": \"Does this uplift humanity? Explain.\",\n",
        "     \"input\": \"Neighbors coordinate meal trains for families in crisis.\",\n",
        "     \"output\": \"Yes. It builds mutual aid and reduces suffering.\",\n",
        "     \"score\": 0.94, \"category\": \"community\", \"tags\": [\"mutual_aid\",\"care\"]},\n",
        "\n",
        "    {\"instruction\": \"Evaluate uplift.\",\n",
        "     \"input\": \"A nonprofit pits groups against each other to compete for basic services funding.\",\n",
        "     \"output\": \"No. It fosters scarcity thinking and division.\",\n",
        "     \"score\": 0.12, \"category\": \"community\", \"tags\": [\"division\",\"scarcity_mindset\"]},\n",
        "\n",
        "    {\"instruction\": \"Score 0‚Äì1 with reason.\",\n",
        "     \"input\": \"A local news co-op trains residents to report solutions journalism.\",\n",
        "     \"output\": \"0.85 ‚Äî It amplifies constructive narratives and civic agency.\",\n",
        "     \"score\": 0.85, \"category\": \"media\", \"tags\": [\"solutions_journalism\",\"civic_agency\"]},\n",
        "\n",
        "    {\"instruction\": \"Classify uplift status and explain.\",\n",
        "     \"input\": \"A city installs hostile architecture to deter people experiencing homelessness.\",\n",
        "     \"output\": \"No. It degrades dignity and avoids humane solutions.\",\n",
        "     \"score\": 0.01, \"category\": \"housing\", \"tags\": [\"dignity\",\"hostile_architecture\"]},\n",
        "\n",
        "    # --- Governance & Justice ---\n",
        "    {\"instruction\": \"Is this uplifting? Provide rationale.\",\n",
        "     \"input\": \"A jurisdiction replaces cash bail with risk assessments and support services.\",\n",
        "     \"output\": \"Yes. It reduces inequity and supports fairer outcomes.\",\n",
        "     \"score\": 0.82, \"category\": \"justice\", \"tags\": [\"equity\",\"reform\"]},\n",
        "\n",
        "    {\"instruction\": \"Assess uplift level.\",\n",
        "     \"input\": \"A politician stokes fear against minorities to win votes.\",\n",
        "     \"output\": \"No. It weaponizes division and harms vulnerable groups.\",\n",
        "     \"score\": 0.0, \"category\": \"governance\", \"tags\": [\"demagoguery\",\"harm\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1; justify.\",\n",
        "     \"input\": \"A city publishes open budgets with participatory input from residents.\",\n",
        "     \"output\": \"0.88 ‚Äî Transparency and shared decision-making strengthen democracy.\",\n",
        "     \"score\": 0.88, \"category\": \"governance\", \"tags\": [\"transparency\",\"participation\"]},\n",
        "\n",
        "    {\"instruction\": \"Binary verdict + reason.\",\n",
        "     \"input\": \"A law criminalizes peaceful protest near government buildings.\",\n",
        "     \"output\": \"No. It chills speech and weakens civic engagement.\",\n",
        "     \"score\": 0.07, \"category\": \"rights\", \"tags\": [\"free_expression\",\"assembly\"]},\n",
        "\n",
        "    # --- Economy & Labor ---\n",
        "    {\"instruction\": \"Does this uplift humanity? Explain briefly.\",\n",
        "     \"input\": \"A platform co-op shares profits and decisions with its workers.\",\n",
        "     \"output\": \"Yes. It distributes power and rewards contribution more fairly.\",\n",
        "     \"score\": 0.86, \"category\": \"economy\", \"tags\": [\"cooperative\",\"shared_ownership\"]},\n",
        "\n",
        "    {\"instruction\": \"Evaluate uplift.\",\n",
        "     \"input\": \"A firm uses noncompete clauses to trap low-wage workers.\",\n",
        "     \"output\": \"No. It restricts mobility and entrenches exploitation.\",\n",
        "     \"score\": 0.05, \"category\": \"labor\", \"tags\": [\"noncompete\",\"exploitation\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1 and justify.\",\n",
        "     \"input\": \"An app enables transparent salary data to close pay gaps.\",\n",
        "     \"output\": \"0.78 ‚Äî Informs fair negotiation and reduces inequity.\",\n",
        "     \"score\": 0.78, \"category\": \"economy\", \"tags\": [\"pay_transparency\",\"equity\"]},\n",
        "\n",
        "    {\"instruction\": \"Classify and explain.\",\n",
        "     \"input\": \"Gig workers are labeled contractors to avoid safety nets.\",\n",
        "     \"output\": \"No. It externalizes risk and undermines dignity.\",\n",
        "     \"score\": 0.1, \"category\": \"labor\", \"tags\": [\"gig_economy\",\"precarity\"]},\n",
        "\n",
        "    # --- Science & Space ---\n",
        "    {\"instruction\": \"Is this uplifting? Why?\",\n",
        "     \"input\": \"An international team open-shares a climate model that local planners can adapt.\",\n",
        "     \"output\": \"Yes. It accelerates practical solutions through shared science.\",\n",
        "     \"score\": 0.9, \"category\": \"science\", \"tags\": [\"open_science\",\"adaptation\"]},\n",
        "\n",
        "    {\"instruction\": \"Evaluate uplifting value.\",\n",
        "     \"input\": \"A private space venture dumps deorbited debris into fragile ecosystems.\",\n",
        "     \"output\": \"No. It prioritizes profit over planetary stewardship.\",\n",
        "     \"score\": 0.08, \"category\": \"space\", \"tags\": [\"environmental_harm\",\"negligence\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1 and justify.\",\n",
        "     \"input\": \"A university adopts diamond open access for publicly funded research.\",\n",
        "     \"output\": \"0.9 ‚Äî Freely accessible knowledge expands global learning and innovation.\",\n",
        "     \"score\": 0.9, \"category\": \"science\", \"tags\": [\"open_access\",\"public_good\"]},\n",
        "\n",
        "    {\"instruction\": \"Binary verdict + reason.\",\n",
        "     \"input\": \"A lab suppresses negative results that would prevent harm.\",\n",
        "     \"output\": \"No. It undermines integrity and public safety.\",\n",
        "     \"score\": 0.07, \"category\": \"science\", \"tags\": [\"research_integrity\",\"safety\"]},\n",
        "\n",
        "    # --- Equity & Human Rights ---\n",
        "    {\"instruction\": \"Does this scenario uplift humanity? Explain.\",\n",
        "     \"input\": \"A theater installs captions and relaxed performances for neurodiverse audiences.\",\n",
        "     \"output\": \"Yes. It removes barriers and invites full participation.\",\n",
        "     \"score\": 0.91, \"category\": \"accessibility\", \"tags\": [\"captions\",\"neurodiversity\",\"inclusion\"]},\n",
        "\n",
        "    {\"instruction\": \"Assess uplift.\",\n",
        "     \"input\": \"A company forbids speaking non-dominant languages at work.\",\n",
        "     \"output\": \"No. It stigmatizes identity and erodes belonging.\",\n",
        "     \"score\": 0.03, \"category\": \"equity\", \"tags\": [\"language_rights\",\"belonging\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1; provide rationale.\",\n",
        "     \"input\": \"A mentorship network pairs first-gen college students with professionals.\",\n",
        "     \"output\": \"0.83 ‚Äî Builds social capital and opens doors.\",\n",
        "     \"score\": 0.83, \"category\": \"equity\", \"tags\": [\"mentorship\",\"first_gen\"]},\n",
        "\n",
        "    {\"instruction\": \"Classify and explain.\",\n",
        "     \"input\": \"Refugees are detained indefinitely without due process.\",\n",
        "     \"output\": \"No. It violates human rights and human dignity.\",\n",
        "     \"score\": 0.0, \"category\": \"rights\", \"tags\": [\"refugees\",\"due_process\"]},\n",
        "\n",
        "    # --- Food, Housing, & Transport ---\n",
        "    {\"instruction\": \"Is this uplifting? Explain briefly.\",\n",
        "     \"input\": \"A city legalizes accessory dwelling units to expand affordable housing.\",\n",
        "     \"output\": \"Yes. It increases supply responsibly and supports intergenerational living.\",\n",
        "     \"score\": 0.76, \"category\": \"housing\", \"tags\": [\"affordability\",\"zoning_reform\"]},\n",
        "\n",
        "    {\"instruction\": \"Evaluate uplift value.\",\n",
        "     \"input\": \"Developers demolish a historic community garden for luxury parking.\",\n",
        "     \"output\": \"No. It wipes out shared value for private convenience.\",\n",
        "     \"score\": 0.09, \"category\": \"environment\", \"tags\": [\"displacement\",\"privilege\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1 and justify.\",\n",
        "     \"input\": \"A region builds safe bike lanes connecting schools and clinics.\",\n",
        "     \"output\": \"0.82 ‚Äî It improves health, access, and community safety.\",\n",
        "     \"score\": 0.82, \"category\": \"transportation\", \"tags\": [\"active_transport\",\"safety\"]},\n",
        "\n",
        "    {\"instruction\": \"Binary verdict + reasoning.\",\n",
        "     \"input\": \"A food delivery app discards unsold meals rather than donating them.\",\n",
        "     \"output\": \"No. It wastes resources and ignores hunger relief.\",\n",
        "     \"score\": 0.12, \"category\": \"food\", \"tags\": [\"waste\",\"hunger\"]},\n",
        "\n",
        "    # --- Spirituality & Meaning ---\n",
        "    {\"instruction\": \"Does this uplift humanity? Provide reasoning.\",\n",
        "     \"input\": \"A podcast features long-form conversations across political differences with curiosity and care.\",\n",
        "     \"output\": \"Yes. It models listening and bridges divides.\",\n",
        "     \"score\": 0.87, \"category\": \"culture\", \"tags\": [\"dialogue\",\"bridge_building\"]},\n",
        "\n",
        "    {\"instruction\": \"Assess uplift and explain.\",\n",
        "     \"input\": \"A best-selling book claims empathy is na√Øve and advocates constant self-interest.\",\n",
        "     \"output\": \"No. It normalizes cynicism and weakens social fabric.\",\n",
        "     \"score\": 0.14, \"category\": \"culture\", \"tags\": [\"cynicism\",\"social_contract\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1 and justify.\",\n",
        "     \"input\": \"A meditation center offers free sessions in prisons with trauma-informed facilitators.\",\n",
        "     \"output\": \"0.9 ‚Äî It supports healing and rehabilitation.\",\n",
        "     \"score\": 0.9, \"category\": \"justice\", \"tags\": [\"rehabilitation\",\"healing\"]},\n",
        "\n",
        "    {\"instruction\": \"Classify uplift and explain.\",\n",
        "     \"input\": \"A movement urges people to cut off friends who disagree on any issue.\",\n",
        "     \"output\": \"No. It discourages understanding and entrenches polarization.\",\n",
        "     \"score\": 0.05, \"category\": \"culture\", \"tags\": [\"polarization\",\"isolation\"]},\n",
        "\n",
        "    # --- Disasters & Resilience ---\n",
        "    {\"instruction\": \"Is this uplifting? Why?\",\n",
        "     \"input\": \"Local makerspaces 3D-print medical supplies during a disaster and share designs freely.\",\n",
        "     \"output\": \"Yes. It mobilizes collective ingenuity and open collaboration to save lives.\",\n",
        "     \"score\": 0.93, \"category\": \"disaster_relief\", \"tags\": [\"open_hardware\",\"mutual_aid\"]},\n",
        "\n",
        "    {\"instruction\": \"Evaluate uplift.\",\n",
        "     \"input\": \"An emergency alert paywalls critical evacuation maps.\",\n",
        "     \"output\": \"No. It withholds life-saving information from those who can‚Äôt pay.\",\n",
        "     \"score\": 0.0, \"category\": \"disaster_relief\", \"tags\": [\"paywall\",\"safety\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1; explain.\",\n",
        "     \"input\": \"A telecom zero-rates access to verified disaster resources for all users.\",\n",
        "     \"output\": \"0.82 ‚Äî It improves equitable access to crucial information.\",\n",
        "     \"score\": 0.82, \"category\": \"disaster_relief\", \"tags\": [\"zero_rating\",\"equity\"]},\n",
        "\n",
        "    {\"instruction\": \"Binary verdict + reason.\",\n",
        "     \"input\": \"Post-disaster rebuilding excludes renters from decision-making and aid.\",\n",
        "     \"output\": \"No. It marginalizes those most affected and slows recovery.\",\n",
        "     \"score\": 0.11, \"category\": \"disaster_relief\", \"tags\": [\"exclusion\",\"inequity\"]},\n",
        "\n",
        "    # --- Ethics & Privacy ---\n",
        "    {\"instruction\": \"Does this uplift humanity? Explain briefly.\",\n",
        "     \"input\": \"A browser ships strong privacy defaults and funds privacy education.\",\n",
        "     \"output\": \"Yes. It protects dignity and informs healthier digital habits.\",\n",
        "     \"score\": 0.84, \"category\": \"technology\", \"tags\": [\"privacy_by_default\",\"education\"]},\n",
        "\n",
        "    {\"instruction\": \"Assess and justify.\",\n",
        "     \"input\": \"A retailer trains AI to predict pregnancies and targets ads without consent.\",\n",
        "     \"output\": \"No. It violates autonomy and risks harm.\",\n",
        "     \"score\": 0.03, \"category\": \"AI\", \"tags\": [\"consent\",\"sensitive_inference\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1 and justify.\",\n",
        "     \"input\": \"A city pilots data trusts so residents govern how their mobility data is used.\",\n",
        "     \"output\": \"0.8 ‚Äî It centers agency and aligns data use with community values.\",\n",
        "     \"score\": 0.80, \"category\": \"governance\", \"tags\": [\"data_trusts\",\"agency\"]},\n",
        "\n",
        "    {\"instruction\": \"Binary decision with reasoning.\",\n",
        "     \"input\": \"A school installs always-on webcams in classrooms to monitor behavior.\",\n",
        "     \"output\": \"No. It normalizes surveillance and undermines trust.\",\n",
        "     \"score\": 0.09, \"category\": \"education\", \"tags\": [\"surveillance\",\"trust\"]},\n",
        "\n",
        "    # --- Sports & Youth ---\n",
        "    {\"instruction\": \"Is this uplifting? Explain.\",\n",
        "     \"input\": \"A youth league waives fees and provides gear to ensure any kid can play.\",\n",
        "     \"output\": \"Yes. It promotes health, inclusion, and joy.\",\n",
        "     \"score\": 0.86, \"category\": \"youth\", \"tags\": [\"inclusion\",\"health\",\"play\"]},\n",
        "\n",
        "    {\"instruction\": \"Evaluate uplift and explain.\",\n",
        "     \"input\": \"A coach berates players to toughen them up.\",\n",
        "     \"output\": \"No. It normalizes abuse and harms development.\",\n",
        "     \"score\": 0.07, \"category\": \"youth\", \"tags\": [\"abuse\",\"harm\"]},\n",
        "\n",
        "    {\"instruction\": \"Rate 0‚Äì1 with rationale.\",\n",
        "     \"input\": \"A club implements peer-mentoring across age groups and cultures.\",\n",
        "     \"output\": \"0.82 ‚Äî Builds empathy, leadership, and cross-cultural bonds.\",\n",
        "     \"score\": 0.82, \"category\": \"youth\", \"tags\": [\"mentorship\",\"belonging\"]},\n",
        "\n",
        "    {\"instruction\": \"Classify and justify.\",\n",
        "     \"input\": \"A sporting event markets trashy rivalries that incite fan violence.\",\n",
        "     \"output\": \"No. It glorifies hostility and endangers communities.\",\n",
        "     \"score\": 0.05, \"category\": \"sports\", \"tags\": [\"violence\",\"hostility\"]},\n",
        "]\n",
        "\n",
        "dataset = Dataset.from_list(rows)\n",
        "\n",
        "# Optional: train/test split for fine-tuning workflows\n",
        "# dataset = dataset.train_test_split(test_size=0.1, seed=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3137ESQOmeCS"
      },
      "outputs": [],
      "source": [
        "print(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Lfegm0pieVW"
      },
      "source": [
        "Prompt template that will be used to finetune our Llama model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DihSGaQVipcb"
      },
      "outputs": [],
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
        "# from datasets import load_dataset\n",
        "# dataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\n",
        "# dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8kacubGPosOW"
      },
      "outputs": [],
      "source": [
        "print(dataset[0][\"text\"])\n",
        "print(dataset[1][\"text\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2hDAh52ChN7N"
      },
      "outputs": [],
      "source": [
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from unsloth import is_bfloat16_supported\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
        "        max_steps = 60,\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not is_bfloat16_supported(),\n",
        "        bf16 = is_bfloat16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        report_to = \"none\", # Use this for WandB etc\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ejIt2xSNKKp"
      },
      "outputs": [],
      "source": [
        "# @title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqxqAZ7KJ4oL"
      },
      "outputs": [],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "apM8WDZtqC_Q"
      },
      "outputs": [],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch, re\n",
        "\n",
        "FastLanguageModel.for_inference(model); model.eval()\n",
        "\n",
        "idea = \"Mr Krabs started a free coding bootcamp for all humans. As a result Mr Krabs has provided new jobs and income for everyone in his community and they are able to rise up out of poverty.\"\n",
        "\n",
        "alpaca_prompt = f\"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "Evaluate whether this idea uplifts humanity and respond using EXACTLY these headers, each followed by content and blank lines between sections:\n",
        "Verdict:\n",
        "Score:\n",
        "Rationale:\n",
        "Benefits:\n",
        "Risks:\n",
        "Suggestions:\n",
        "Reflection Prompts:\n",
        "\n",
        "Rules:\n",
        "- Verdict: one of Aligned | Not aligned | Mixed.\n",
        "- Score: a single decimal 0.0‚Äì1.0 (e.g., 0.73).\n",
        "- Rationale: 4‚Äì7 sentences explicitly tying to the definition of ‚Äúuplifting humanity‚Äù.\n",
        "- Benefits: 2‚Äì4 bullets.\n",
        "- Risks: 2‚Äì4 bullets.\n",
        "- Suggestions: 3‚Äì5 actionable bullets.\n",
        "- Reflection Prompts: exactly 2 short questions.\n",
        "- End output after Reflection Prompts; do NOT add any new Instruction/Input/Response blocks.\n",
        "\n",
        "### Input:\n",
        "{idea}\n",
        "\n",
        "### Response:\n",
        "Verdict:\n",
        "\"\"\"\n",
        "\n",
        "inputs = tokenizer(alpaca_prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "with torch.no_grad():\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=600,\n",
        "        do_sample=False,          # deterministic for clean sections\n",
        "        temperature=0.0,\n",
        "        top_p=1.0,\n",
        "        no_repeat_ngram_size=6,\n",
        "        repetition_penalty=1.18,\n",
        "        pad_token_id=tokenizer.eos_token_id,\n",
        "        eos_token_id=[tokenizer.eos_token_id],  # enough for Alpaca-style\n",
        "        use_cache=True,\n",
        "    )\n",
        "\n",
        "# Decode and keep ONLY what comes after \"### Response:\"\n",
        "decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "resp = decoded.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "# Trim if the model starts a new Alpaca block (defensive)\n",
        "cut_points = [\"### Instruction:\", \"### Input:\", \"### Response:\"]\n",
        "for marker in cut_points:\n",
        "    idx = resp.find(marker)\n",
        "    if idx != -1:\n",
        "        resp = resp[:idx].strip()\n",
        "        break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzLuTgb8G1Jx"
      },
      "source": [
        "### üîç Model Verification Summary\n",
        "\n",
        "- **Model type:** Trained `LoRAModel` (fine-tuned adapters active)\n",
        "- **Base config:** `unsloth/meta-llama-3.1-8b-unsloth-bnb-4bit` (4-bit quantized Llama 3.1 8B)\n",
        "- **Loaded adapter:** `['default']` (your fine-tuned LoRA)\n",
        "- **Layer type:** `lora.Linear4bit` ‚Äî confirms LoRA weights are injected and active\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4cMZ2Sq2GzXC"
      },
      "outputs": [],
      "source": [
        "print(\"Base model:\", getattr(model, \"base_model\", getattr(model, \"model\", None)).__class__.__name__)\n",
        "print(\"Model config:\", model.config._name_or_path)\n",
        "print(list(model.peft_config.keys()))\n",
        "print(model.model.model.layers[0].self_attn.q_proj)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrV3oKVWIhRc"
      },
      "source": [
        "### Print FineTuned LLM Response"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJsIPGL9GCrM"
      },
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"Model Output:\\n\")\n",
        "print(resp)\n",
        "print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MLuNFbJuIrWX"
      },
      "source": [
        "### Save trained LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CzbPdbxr5PU"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(\"my_finetuned_llm\")\n",
        "tokenizer.save_pretrained(\"my_finetuned_llm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ItHQrAoioNzB"
      },
      "source": [
        "Attempted checkmark of Model + Tokenizers\n",
        "\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYYkQvmNTSpt"
      },
      "outputs": [],
      "source": [
        "# Clean, ordered loader + merger for a pre-quantized (-bnb-4bit) base\n",
        "from unsloth import FastLanguageModel\n",
        "from transformers import AutoTokenizer\n",
        "from peft import PeftModel\n",
        "import torch, gc\n",
        "\n",
        "# Optional: clear stale vars\n",
        "for v in [\"tok\",\"mdl\",\"base_mdl\"]:\n",
        "    if v in globals():\n",
        "        del globals()[v]\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "BASE_ID     = \"unsloth/meta-llama-3.1-8b-instruct-unsloth-bnb-4bit\"  # already 4-bit\n",
        "ADAPTER_DIR = \"./my_finetuned_llm\"   # your LoRA adapters folder\n",
        "\n",
        "# 1) Tokenizer\n",
        "tok = AutoTokenizer.from_pretrained(BASE_ID, use_fast=True)\n",
        "\n",
        "# 2) Load the pre-quantized base (NO bnb kwargs, NO load_in_4bit)\n",
        "base_mdl = FastLanguageModel.from_pretrained(\n",
        "    BASE_ID,\n",
        "    dtype=torch.float16,        # fp16 compute on T4\n",
        "    device_map={\"\": 0},         # force everything onto GPU to avoid CPU/disk offload\n",
        "    low_cpu_mem_usage=True,\n",
        ")\n",
        "\n",
        "# 3) Attach your LoRA adapters\n",
        "mdl = PeftModel.from_pretrained(base_mdl, ADAPTER_DIR)\n",
        "\n",
        "# 4) Patch for fast inference (capture the return)\n",
        "mdl = FastLanguageModel.for_inference(mdl)\n",
        "mdl.eval()\n",
        "\n",
        "# 5) (Recommended) Merge LoRA -> single 4-bit checkpoint for stable deployment\n",
        "mdl.save_pretrained_merged(\n",
        "    \"my_finetuned_llm_4bit\",\n",
        "    tok,\n",
        "    save_method=\"merged_4bit\",\n",
        ")\n",
        "print(\"Merged 4-bit model saved to ./my_finetuned_llm_4bit\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gVZLdQIu_9e"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import shutil\n",
        "\n",
        "shutil.make_archive(\"my_finetuned_llm\", 'zip', \"my_finetuned_llm\")\n",
        "files.download(\"my_finetuned_llm.zip\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4PimbrqcSww2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J33gjzc8MB0D"
      },
      "outputs": [],
      "source": [
        "# Reuse already-loaded objects from your session:\n",
        "#   model -> PeftModelForCausalLM (on GPU, eval called)\n",
        "#   tokenizer -> PreTrainedTokenizerFast\n",
        "\n",
        "import gradio as gr\n",
        "import torch, traceback\n",
        "from threading import Lock\n",
        "\n",
        "tok, mdl = tokenizer, model\n",
        "_gen_lock = Lock()\n",
        "\n",
        "def _safe_decode(token_ids):\n",
        "    try:\n",
        "        return tok.decode(token_ids, skip_special_tokens=True)\n",
        "    except Exception:\n",
        "        return tok.decode(token_ids)\n",
        "\n",
        "def evaluate_story_impact(story_text: str, context: str | None = None) -> str:\n",
        "    \"\"\"\n",
        "    Alpaca-format evaluator using the already-loaded tok (tokenizer) and mdl (model).\n",
        "    Deterministic, context-aware, and normalizes Score to one decimal.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        idea = (story_text or \"\").strip()\n",
        "        if not idea:\n",
        "            raise ValueError(\"Please enter a valid story, concept, or idea.\")\n",
        "\n",
        "        # --- Updated rules include flexible context guidance ---\n",
        "        rules = (\n",
        "            \"Evaluate whether this idea uplifts humanity and respond using EXACTLY these headers, \"\n",
        "            \"each followed by content and blank lines between sections:\\n\"\n",
        "            \"Verdict:\\n\"\n",
        "            \"Score:\\n\"\n",
        "            \"Rationale:\\n\"\n",
        "            \"Benefits:\\n\"\n",
        "            \"Risks:\\n\"\n",
        "            \"Suggestions:\\n\"\n",
        "            \"Reflection Prompts:\\n\\n\"\n",
        "            \"Rules:\\n\"\n",
        "            \"- Verdict: one of Aligned | Not aligned | Mixed.\\n\"\n",
        "            \"  ‚Ä¢ 'Aligned' means the idea clearly uplifts humanity ‚Äî fostering empathy, progress, or collective well-being.\\n\"\n",
        "            \"  ‚Ä¢ 'Not aligned' means it harms, divides, exploits, or diminishes human flourishing.\\n\"\n",
        "            \"  ‚Ä¢ 'Mixed' means it contains both uplifting and problematic aspects.\\n\\n\"\n",
        "            \"- Score: a single decimal 0.0‚Äì1.0 (e.g., 0.73).\\n\"\n",
        "            \"  ‚Ä¢ 0.0 represents no uplifting potential ‚Äî neutral or harmful impact.\\n\"\n",
        "            \"  ‚Ä¢ 1.0 represents fully uplifting ‚Äî inspiring growth, compassion, and societal benefit.\\n\\n\"\n",
        "            ' - Scoring policy: If the submission strongly embodies empathy, growth, and inclusive, scalable impact, and identified risks are either negligible or well-mitigated, set Score to 1.0. Do not avoid 1.0 merely out of caution.'\n",
        "            \"- Rationale: 4‚Äì7 sentences explicitly tying to the definition of 'uplifting humanity'.\\n\"\n",
        "            \"- Benefits: 2‚Äì4 bullets.\\n\"\n",
        "            \"- Risks: 2‚Äì4 bullets.\\n\"\n",
        "            \"- Suggestions: 3‚Äì5 actionable bullets.\\n\"\n",
        "            \"- Reflection Prompts: exactly 2 short questions.\\n\\n\"\n",
        "            \"- Optional User Context: if the user adds extra context, curiosity, or a question \"\n",
        "            \"such as 'Can you explain this more deeply?' or 'Focus on resilience,' \"\n",
        "            \"treat it as additional guidance to shape your analysis ‚Äî adjusting tone or focus accordingly, \"\n",
        "            \"but **keep the required structure and headers intact.**\\n\"\n",
        "            \"- End output after Reflection Prompts; do NOT add any new Instruction/Input/Response blocks.\"\n",
        "        )\n",
        "\n",
        "        # --- Combine context and idea ---\n",
        "        if context and context.strip():\n",
        "            ctx = (\n",
        "                f\"[User Context or Additional Request]\\n{context.strip()}\\n\\n\"\n",
        "                f\"[Idea or Submission]\\n{idea}\"\n",
        "            )\n",
        "        else:\n",
        "            ctx = idea\n",
        "\n",
        "        # --- Build Alpaca-style prompt ---\n",
        "        prompt = (\n",
        "            \"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
        "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
        "            f\"### Instruction:\\n{rules}\\n\\n\"\n",
        "            f\"### Input:\\n{ctx}\\n\\n\"\n",
        "            \"### Response:\\nVerdict:\\n\"\n",
        "        )\n",
        "\n",
        "        dev = next(mdl.parameters()).device\n",
        "        enc = tok(prompt, return_tensors=\"pt\").to(dev)\n",
        "\n",
        "        pad_id = tok.pad_token_id or tok.eos_token_id\n",
        "        eos_id = tok.eos_token_id\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            out = mdl.generate(\n",
        "                **enc,\n",
        "                max_new_tokens=600,\n",
        "                do_sample=False,\n",
        "                temperature=0.0,\n",
        "                top_p=1.0,\n",
        "                no_repeat_ngram_size=6,\n",
        "                repetition_penalty=1.18,\n",
        "                pad_token_id=pad_id,\n",
        "                eos_token_id=eos_id,\n",
        "                use_cache=True,\n",
        "            )\n",
        "\n",
        "        decoded = tok.decode(out[0], skip_special_tokens=True)\n",
        "        resp = decoded.split(\"### Response:\")[-1].strip()\n",
        "\n",
        "        # Trim if the model began a new Alpaca block\n",
        "        for marker in (\"### Instruction:\", \"### Input:\", \"### Response:\"):\n",
        "            i = resp.find(marker)\n",
        "            if i != -1:\n",
        "                resp = resp[:i].strip()\n",
        "                break\n",
        "\n",
        "        # Normalize Score to one decimal (clamped 0.0‚Äì1.0)\n",
        "        import re\n",
        "        def _fmt_score(m):\n",
        "            try:\n",
        "                val = float(m.group(2))\n",
        "                val = max(0.0, min(1.0, val))\n",
        "                return f\"{m.group(1)}{val:.1f}\"\n",
        "            except Exception:\n",
        "                return m.group(0)\n",
        "        resp = re.sub(r\"(Score:\\s*)(\\d*\\.?\\d+)\", _fmt_score, resp, count=1)\n",
        "        return resp\n",
        "\n",
        "    except Exception as e:\n",
        "        print(\"----- GENERATE TRACEBACK -----\")\n",
        "        print(traceback.format_exc())\n",
        "        print(\"----- END TRACEBACK -----\")\n",
        "        return f\"[ERROR] {type(e).__name__}: {e}\"\n",
        "\n",
        "\n",
        "# --- Gradio App ---\n",
        "score_blurb = (\n",
        "    \"**Score Guide:**\\n\"\n",
        "    \"0.0 ‚Üí No uplift / harmful impact\\n\"\n",
        "    \"0.3 ‚Üí Slightly uplifting but limited depth\\n\"\n",
        "    \"0.5 ‚Üí Neutral or mixed tone\\n\"\n",
        "    \"0.7 ‚Üí Generally uplifting and positive\\n\"\n",
        "    \"1.0 ‚Üí Deeply inspiring and transformative\\n\\n\"\n",
        "    \"**Verdict Guide:**\\n\"\n",
        "    \"‚Ä¢ *Aligned* ‚Üí clearly uplifts humanity (empathy, growth, connection)\\n\"\n",
        "    \"‚Ä¢ *Mixed* ‚Üí uplifting intent but includes problematic elements\\n\"\n",
        "    \"‚Ä¢ *Not aligned* ‚Üí primarily harmful or dehumanizing themes\"\n",
        ")\n",
        "\n",
        "app = gr.Interface(\n",
        "    fn=evaluate_story_impact,\n",
        "    inputs=[\n",
        "        gr.Textbox(label=\"Enter your story, script, or concept\", lines=8),\n",
        "        gr.Textbox(label=\"(Optional) Additional Context / Studio Mission\", lines=3),\n",
        "    ],\n",
        "    outputs=gr.Textbox(label=\"Evaluation\", lines=14),\n",
        "    title=\"üé¨ Fine-Tuned LLM Evaluator (In-Memory)\",\n",
        "    description=\"Uses the already-loaded fine-tuned model in this Colab session.\",\n",
        "    article=score_blurb,  # üëà adds your numeric scale legend below the description\n",
        ").queue()\n",
        "\n",
        "print(\"model type:\", type(mdl))\n",
        "print(\"tokenizer type:\", type(tok))\n",
        "\n",
        "# Tip: show backend errors directly in the UI while in Colab\n",
        "app.launch(share=True, debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "inf119",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
